{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Softmax \n",
    "\n",
    "For **multi-class** classification: $ p(y=c|x), c\\in[0, 1, 2, ...]$, we use the softmax activation function at the output\n",
    "\n",
    "$$o(a) = softmax(a) = [\\cfrac{exp(a_1)}{\\Sigma_cexp(a_c)} , \\cfrac{exp(a_2)}{\\Sigma_cexp(a_c)} , ... ,  \\cfrac{exp(a_c)}{\\Sigma_cexp(a_c)}]^T   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8360188   0.11314284  0.05083836]\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "scores = [3.0, 1.0, 0.2]\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Softmax overflow. \n",
    " \n",
    "对于x的值很大的时候，由于作指数计算$e^x$, 数据值会很大，容易发生溢出，所以在作softmax时，一个推荐的算法应该是尽可能减小x的值。比如:都减去一个max(x), say m \n",
    "\n",
    "$$ \\cfrac{e^{x_i-m}}{\\Sigma e^{x_i-m}} = \\cfrac{e^{x_i}/e^m}{\\Sigma e^{x_i}/e^m} = \\cfrac{e^{x_i}}{\\Sigma e^{x_i}} $$\n",
    "\n",
    "\n",
    "当然我们不必一定要减去一个最大数，比如可以减去一个平均数，在某些场合也是合适的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8360188 ,  0.11314284,  0.05083836])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # 注意axis=0, 使得该方法可以扩展到2维\n",
    "\n",
    "scores = [3.0, 1.0, 0.2]\n",
    "softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09003057,  0.00242826,  0.01587624,  0.33333333],\n",
       "       [ 0.24472847,  0.01794253,  0.11731043,  0.33333333],\n",
       "       [ 0.66524096,  0.97962921,  0.86681333,  0.33333333]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2D = np.array([[1, 2, 3, 6],\n",
    "                     [2, 4, 5, 6],\n",
    "                     [3, 8, 7, 6]])\n",
    "softmax(scores2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
