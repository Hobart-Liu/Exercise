{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对熵又称互熵，交叉熵，鉴别信息，Kullback熵，Kullback-Leible散度（即KL散度）等\n",
    "\n",
    "设p(x) 和 q(x) 是X取值的2个概率分布。则p对q的相对熵为 $D(p\\mid\\mid q)= sum_{i=1}^n p(x)log\\cfrac{p(x)}{q(x)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在一定程度上，熵可以度量两个随机变量的距离。KL散度是两个概率分布P和Q差别的非对称性的度量。KL散度是用来度量使用基于Q的编码来编码来自P的样本平均所需的额外的位元数。 典型情况下，P表示数据的真实分布，Q表示数据的理论分布，模型分布，或P的近似分布。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对熵（KL散度）有两个主要的性质。如下\n",
    " \n",
    "- 尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即\n",
    " \n",
    "$ D(p\\mid\\mid q) \\neq D(q\\mid\\mid p) $\n",
    " \n",
    "- 相对熵的值为非负值，即在证明之前，需要认识一个重要的不等式，叫做吉布斯不等式\n",
    "\n",
    "若$\\sum_{i=1}^n p_i = \\sum_{i=1}^n q_i = 1$ 且 $p_i, q_i \\in (0,1]$ \n",
    "\n",
    "则有：$-\\sum_{i=1}^n p_i \\log p_i \\leq -\\sum_{i=1}^n p_i \\log q_i$ 等号成立当且仅当$p_i = q_i \\forall i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "吉布斯不等式等价于：\n",
    "$ 0 \\geq \\sum_{i=1}^n p_i\\log q_i - \\sum_{i=1}^n p_i \\log p_i = \\sum_{i=1}^n p_i\\log(q_i/p_i) = -D_{KL}(P\\mid\\mid Q) $\n",
    "\n",
    "证明：\n",
    "已知$\\ln(x) \\leq x-1$ 等号成立当且仅当x=1\n",
    "$\\sum_{i=1}^n pi\\log(q_i/p_i) \\leq \\sum_{i=1}^n p_i(q_i/p_i-1) = \\sum_{i=1}^n (q_i-p_i) = \\sum_{i=1}^n q_i - \\sum_{i=1}^n p_i = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
